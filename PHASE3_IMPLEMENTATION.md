# Phase 3 Implementation: Memory & Planning

**Status**: âœ… COMPLETE
**Date**: 2025-11-17

---

## Overview

Phase 3 implements the **intelligence layer** for AI players using LLM-powered planning, hierarchical memory, and skill learning. This transforms AI players from simple random walkers into intelligent agents capable of goal-directed behavior.

## Architecture

### Core Principle: ReAct Framework

The AI uses the **ReAct** (Reasoning + Acting) framework:

1. **Observe**: Perceive world state + recall relevant memories
2. **Think**: LLM reasons about situation and generates goals
3. **Plan**: Decompose goals into task sequences
4. **Act**: Execute tasks using action controllers
5. **Reflect**: Store outcomes in memory, update skill ratings

### Intelligence Systems

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AIPlayerBrain                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Memory    â”‚  â”‚   Planning   â”‚  â”‚    Skills    â”‚   â”‚
â”‚  â”‚   System    â”‚â—„â”€â”¤    Engine    â”‚â—„â”€â”¤   Library    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â–²                â–²                              â”‚
â”‚         â”‚                â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚ WorldState    â”‚  â”‚   LLM    â”‚                       â”‚
â”‚  â”‚  (Perception) â”‚  â”‚ Provider â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Components Implemented

### 1. Memory System (Cognitive Architecture)

Inspired by human cognition, three-tier memory:

#### **Working Memory** (`WorkingMemory.java`)
- **Purpose**: Short-term context (like human working memory)
- **Capacity**: 20 items max (based on cognitive psychology: 7Â±2)
- **Duration**: 10 minutes
- **Strategy**: FIFO with recency priority
- **Usage**: Current decision context for LLM

#### **Episodic Memory** (`EpisodicMemory.java`)
- **Purpose**: "What happened, when, where"
- **Storage**: Chronological deque + type indices
- **Capacity**: Configurable (default: 1000)
- **Features**:
  - Text search across memories
  - Type-based retrieval
  - Time-range queries
  - Importance-based ranking
  - Automatic consolidation (removes old, low-importance items)

#### **Semantic Memory** (`SemanticMemory.java`)
- **Purpose**: "Facts, relationships, patterns"
- **Contents**:
  - **Facts**: Key-value pairs (e.g., "spawn_location" â†’ "(100, 64, 200)")
  - **Relationships**: Player trust scores (0-100)
  - **Strategies**: Success rate tracking for behaviors
- **Features**:
  - Relationship updates (trust building)
  - Strategy rating (learn what works)
  - Pattern recognition

#### **Memory Coordinator** (`MemorySystem.java`)
- **Purpose**: Unified interface to all memory tiers
- **Features**:
  - Automatic routing (important/recent â†’ working memory)
  - Context formatting for LLM
  - Periodic cleanup
  - Memory statistics

**Code Example**:
```java
// Store perception
memorySystem.store(new Memory(
    Memory.MemoryType.OBSERVATION,
    "Low health: 4.5/20",
    0.9  // High importance
));

// Retrieve for decision making
List<Memory> context = memorySystem.getWorkingMemory().getRecent(10);
String llmContext = memorySystem.formatRecentForContext(5);
```

---

### 2. Goal & Task System

#### **Goal** (`Goal.java`)
Hierarchical goal structure:

```java
public enum GoalType {
    SURVIVAL,          // Find food, heal, escape danger
    EXPLORATION,       // Discover new areas
    RESOURCE_GATHERING, // Mine, collect items
    BUILD,             // Construct structures
    COMBAT,            // Fight mobs
    SOCIAL,            // Interact with players
    CRAFTING           // Create items
}

public enum GoalStatus {
    PENDING,      // Not started
    IN_PROGRESS,  // Currently working on
    COMPLETED,    // Successfully finished
    FAILED,       // Could not complete
    CANCELLED     // Abandoned
}
```

**Features**:
- Subgoal hierarchy (goals can have subgoals)
- Priority ranking (1-10)
- Progress tracking
- Automatic completion detection

#### **Task** (`Task.java`)
Executable work units:

```java
Task task = new Task("Mine 10 logs");
task.addAction("Find nearest tree");
task.addAction("Pathfind to tree");
task.addAction("Mine logs");
task.setGoal(parentGoal);
```

---

### 3. LLM Integration

#### **LLM Provider Interface** (`LLMProvider.java`)
Abstract interface supporting multiple backends:

```java
public interface LLMProvider {
    CompletableFuture<String> complete(String prompt, LLMOptions options);
    CompletableFuture<List<String>> completeBatch(List<String> prompts, ...);
    boolean isAvailable();
    String getModelName();
    String getProviderName();
}
```

#### **Provider Implementations**

**OpenAI Provider** (`OpenAIProvider.java`)
- **Models**: GPT-4, GPT-4 Turbo, GPT-3.5 Turbo
- **API**: OpenAI Chat Completions API
- **Features**:
  - Async requests with CompletableFuture
  - System prompts
  - Temperature/top-p control
  - Stop sequences
  - Batch processing (parallel)

**Claude Provider** (`ClaudeProvider.java`)
- **Models**: Claude 3.5 Sonnet, Claude 3 Haiku, Claude 3 Opus
- **API**: Anthropic Messages API
- **Features**: Same as OpenAI + Claude-specific system prompts

**Local LLM Provider** (`LocalLLMProvider.java`)
- **Backend**: Ollama (http://localhost:11434)
- **Models**: Mistral, LLaMA 2, CodeLlama, Phi-2, etc.
- **Features**:
  - Streaming response handling
  - Model pulling (auto-download)
  - Sequential batch processing (GPU-friendly)
  - No API key required

#### **LLM Options** (`LLMOptions.java`)
Generation parameter control:

```java
LLMOptions options = new LLMOptions()
    .temperature(0.7)
    .maxTokens(1500)
    .topP(1.0)
    .systemPrompt("You are a helpful Minecraft AI...");

// Presets
LLMOptions.planning();      // temp=0.7, tokens=1500
LLMOptions.chat();          // temp=0.8, tokens=500
LLMOptions.deterministic(); // temp=0.0, tokens=1000
```

#### **LLM Cache** (`LLMCache.java`)
Response caching to reduce costs:

- **Cache Key**: hash(prompt + system + temperature + model)
- **Size**: 1000 entries (~10MB)
- **Eviction**: LRU (Least Recently Used)
- **Expiration**: 1 hour
- **Statistics**: Hit rate tracking

**Example**:
```java
LLMProvider provider = new OpenAIProvider(apiKey, "gpt-4-turbo");
LLMCache cache = new LLMCache(provider);

// First call: API request ($$$)
String response1 = cache.complete("Find food", options).get();

// Second call: Cached (free!)
String response2 = cache.complete("Find food", options).get();

// Cache stats: hits=1, misses=1, hit_rate=50%
```

#### **LLM Factory** (`LLMFactory.java`)
Easy provider creation from config:

```java
LLMProvider provider = LLMFactory.create(
    "openai",           // or "claude", "local"
    apiKey,
    "gpt-4-turbo",
    null,
    true                // enable caching
);
```

---

### 4. Planning Engine

**PlanningEngine** (`PlanningEngine.java`)

The brain's "executive function" - generates plans using LLM.

#### Planning Loop

```
1. Update (every 5 seconds):
   â”œâ”€ Check current goals
   â”œâ”€ Update goal status
   â””â”€ Trigger replan if needed

2. Replan:
   â”œâ”€ Build context (world state + memories + current goals)
   â”œâ”€ Send to LLM with system prompt
   â”œâ”€ Parse response for goals/tasks
   â”œâ”€ Add new goals to queue
   â””â”€ Store planning event in memory

3. Execute:
   â”œâ”€ Get highest priority goal
   â”œâ”€ Decompose into tasks
   â”œâ”€ Execute via action controllers
   â””â”€ Update goal status
```

#### LLM Context Format

```
## Current Status
Position: 100.5, 64.0, 200.3
Health: 15.5/20
Hunger: 8.0/20

## Nearby Entities
- cow (distance: 5.2)
- pig (distance: 8.7)

## Recent Memories
- [OBSERVATION] Low hunger: 8.0/20
- [ACTION] Moved to (105, 64, 195)

## Current Goals
- [IN_PROGRESS] Find food (priority: 8)

## Task
Based on the current situation, what should I do next?
Provide your response in this format:
THOUGHT: <reasoning>
GOAL: <description>
PRIORITY: <1-10>
TASKS: <task list>
```

#### Response Parsing

The engine extracts goals using regex:

```
THOUGHT: The AI is hungry and there are cows nearby.
GOAL: Hunt cow for food
PRIORITY: 8
TASKS:
  1. Move towards nearest cow
  2. Kill cow
  3. Collect meat
  4. Cook and eat
```

Parsed into:
```java
Goal goal = new Goal("Hunt cow for food", GoalType.SURVIVAL, 8);
```

---

### 5. Skill Library

**Inspired by Voyager's self-improving skill system**.

#### **Skill** (`Skill.java`)

Learned behaviors with success tracking:

```java
Skill skill = new Skill(
    "Mine Logs",
    "Find and mine the nearest tree to collect logs",
    Skill.SkillCategory.MINING,
    2  // complexity
);

skill.addPrerequisite("None");
skill.addStep("Scan for nearby logs");
skill.addStep("Pathfind to nearest log");
skill.addStep("Mine the log block");
skill.addStep("Collect dropped items");

// Track usage
skill.recordUse(true);  // success
skill.getSuccessRate(); // 1.0 (100%)
skill.getQualityScore(); // 0-100 based on success rate + experience + recency
```

**Categories**:
- MINING (breaking blocks)
- BUILDING (placing blocks)
- CRAFTING (creating items)
- COMBAT (fighting mobs)
- SURVIVAL (food, health, safety)
- EXPLORATION (navigation, discovery)
- SOCIAL (player interaction)
- FARMING (crops, animals)
- UTILITY (general)

#### **SkillLibrary** (`SkillLibrary.java`)

Manages all learned skills:

```java
SkillLibrary library = new SkillLibrary();

// Add custom skill
library.addSkill(new Skill(...));

// Retrieve skills
List<Skill> miningSkills = library.getSkillsByCategory(MINING);
List<Skill> reliableSkills = library.getReliableSkills(); // success >= 70%
List<Skill> topSkills = library.getTopSkills(10);

// Find relevant skills (keyword matching)
List<Skill> relevant = library.findRelevantSkills("find food", 5);

// Get statistics
LibraryStats stats = library.getStats();
// Stats{skills=5, uses=127, successes=98, avgSuccessRate=77.2%}
```

**Initial Skills** (5 basic skills preloaded):
1. Mine Logs (MINING, complexity: 2)
2. Find Food (SURVIVAL, complexity: 3)
3. Explore Safely (EXPLORATION, complexity: 4)
4. Fight Hostile Mob (COMBAT, complexity: 6)
5. Build Simple Shelter (BUILDING, complexity: 5)

**Phase 5 Enhancement**:
- LLM-generated skills (AI writes its own code!)
- Skill composition (combine skills)
- Skill refinement (improve based on failures)

---

### 6. Updated AI Brain

**AIPlayerBrain** (`AIPlayerBrain.java`)

Now supports two modes:

#### **Intelligent Mode** (with LLM)

```java
LLMProvider llm = LLMFactory.create("openai", apiKey, "gpt-4-turbo", null, true);
AIPlayerBrain brain = new AIPlayerBrain(player, llm);
// â†’ INTELLIGENT mode with memory + planning + skills
```

**Decision Loop**:
```
1. Perceive world state
2. Store important observations in memory
3. Update planning engine
4. Get current goal from planner
5. Execute goal-specific behavior:
   â”œâ”€ SURVIVAL â†’ Find food, heal
   â”œâ”€ EXPLORATION â†’ Random walk
   â”œâ”€ COMBAT â†’ Engage hostile mobs
   â”œâ”€ RESOURCE_GATHERING â†’ Mine, collect
   â””â”€ BUILD â†’ Construct (Phase 4)
6. Periodic memory cleanup
```

#### **Simple Mode** (fallback)

```java
AIPlayerBrain brain = new AIPlayerBrain(player);
// â†’ SIMPLE mode (random walk)
```

Uses Phase 1 random walk if LLM is unavailable.

---

## File Summary

### New Files (18 total)

| File | Lines | Purpose |
|------|-------|---------|
| **Planning** |
| `planning/Goal.java` | 180 | Goal hierarchy with types, status, subgoals |
| `planning/Task.java` | 160 | Executable tasks with action sequences |
| `planning/PlanningEngine.java` | 360 | LLM-powered planning (ReAct framework) |
| **Memory** |
| `memory/Memory.java` | 150 | Single memory entry with metadata |
| `memory/MemorySystem.java` | 200 | Memory coordinator (3-tier system) |
| `memory/EpisodicMemory.java` | 146 | Chronological event storage |
| `memory/SemanticMemory.java` | 154 | Facts, relationships, strategy ratings |
| `memory/WorkingMemory.java` | 85 | Short-term context |
| **LLM** |
| `llm/LLMProvider.java` | 51 | Provider interface |
| `llm/LLMOptions.java` | 95 | Generation parameters |
| `llm/OpenAIProvider.java` | 180 | OpenAI GPT-4/GPT-3.5 integration |
| `llm/ClaudeProvider.java` | 178 | Anthropic Claude integration |
| `llm/LocalLLMProvider.java` | 235 | Ollama (local models) integration |
| `llm/LLMCache.java` | 185 | Response caching (cost reduction) |
| `llm/LLMFactory.java` | 120 | Provider creation helper |
| **Skills** |
| `skills/Skill.java` | 220 | Learned behavior with success tracking |
| `skills/SkillLibrary.java` | 285 | Skill storage and retrieval |
| **Updated** |
| `core/AIPlayerBrain.java` | 427 | Now with memory + planning + skills |

**Total**: ~3,391 new lines of code

---

## Usage Examples

### Basic Setup (OpenAI)

```java
// Create LLM provider
LLMProvider llm = LLMFactory.create(
    "openai",
    System.getenv("OPENAI_API_KEY"),
    "gpt-4-turbo",
    null,
    true  // enable caching
);

// Create AI player with intelligent brain
AIPlayerEntity player = new AIPlayerEntity(server, world, profile, llm);

// Player will now:
// - Store memories of important events
// - Generate goals using LLM
// - Execute goal-directed behavior
// - Learn from successes/failures
```

### Basic Setup (Local with Ollama)

```bash
# Install Ollama
curl https://ollama.ai/install.sh | sh

# Pull a model
ollama pull mistral

# Run Ollama server
ollama serve
```

```java
// Create local LLM provider
LLMProvider llm = LLMFactory.create(
    "local",
    null,  // no API key needed
    "mistral",
    "http://localhost:11434",
    true
);

AIPlayerEntity player = new AIPlayerEntity(server, world, profile, llm);
// Same intelligent behavior, but free and private!
```

### Accessing Intelligence Systems

```java
AIPlayerBrain brain = player.getBrain();

// Check mode
if (brain.isIntelligentMode()) {
    // Memory access
    MemorySystem memory = brain.getMemorySystem();
    List<Memory> recent = memory.getRecentMemories(10);
    int trustScore = memory.getSemanticMemory().getRelationship("Steve");

    // Planning access
    PlanningEngine planner = brain.getPlanningEngine();
    Optional<Goal> currentGoal = planner.getCurrentGoal();

    // Skills access
    SkillLibrary skills = brain.getSkillLibrary();
    List<Skill> miningSkills = skills.getSkillsByCategory(MINING);
    LibraryStats stats = skills.getStats();
}
```

---

## Performance & Costs

### Memory Usage

- **Working Memory**: ~2 KB (20 entries Ã— 100 bytes)
- **Episodic Memory**: ~100 KB (1000 entries Ã— 100 bytes)
- **Semantic Memory**: ~10 KB (facts, relationships, strategies)
- **LLM Cache**: ~10 MB (1000 cached responses Ã— 10 KB)
- **Skill Library**: ~5 KB (basic skills)

**Total per AI player**: ~10-15 MB

### API Costs (with caching)

**OpenAI GPT-4 Turbo**:
- Without cache: ~$0.03 per decision ($1.80/hour @ 5s interval)
- With 50% hit rate: ~$0.015 per decision ($0.90/hour)
- With 80% hit rate: ~$0.006 per decision ($0.36/hour)

**Anthropic Claude 3.5 Sonnet**:
- Without cache: ~$0.015 per decision ($0.90/hour)
- With 50% hit rate: ~$0.0075 per decision ($0.45/hour)

**Local (Ollama)**:
- Free! (requires local GPU)
- Mistral 7B: ~2-5s per decision
- LLaMA 2 13B: ~5-10s per decision

### CPU/GPU Usage

- **Planning**: Runs every 5 seconds (not every tick)
- **Memory**: O(1) for add, O(log n) for search
- **LLM calls**: Async (non-blocking)
- **Cache lookups**: O(1) with Caffeine

**Impact**: Minimal (~2-5% extra CPU with caching)

---

## Testing & Validation

### Manual Testing

```
# Start server with AI player
/aiplayer spawn TestBot

# Check status (should show goal-based behavior)
/aiplayer status TestBot

# Observe behavior:
# - Should form goals based on situation
# - Low health â†’ seek food
# - Nearby mobs â†’ fight or flee
# - No threats â†’ explore
```

### Debugging Commands

**Get memory stats**:
```java
brain.getMemorySystem().getStats();
// â†’ MemoryStats{episodic=42, semantic=15, working=8}
```

**Get skill stats**:
```java
brain.getSkillLibrary().getStats();
// â†’ LibraryStats{skills=5, uses=127, avgSuccessRate=77.2%}
```

**Get cache stats**:
```java
((LLMCache) llm).getStats();
// â†’ CacheStats{hits=45, misses=23, hitRate=66.2%}
```

---

## Known Limitations

1. **Goal Execution**: Phase 3 uses simplified goal execution. Full task decomposition comes in Phase 4.

2. **Skill Generation**: Skills are manually defined for now. Phase 5 will add LLM-generated skills.

3. **Memory Retrieval**: Uses simple text search. Phase 5 will add semantic search with embeddings.

4. **Context Window**: Limited to recent memories (~500 tokens). Phase 4 will add smart context selection.

5. **Multi-Agent**: No coordination yet. Phase 5 will add collaborative planning.

---

## Next Steps (Phase 4)

Phase 4 will implement **Natural Language Communication**:

1. **Chat System**: AI players respond to player messages
2. **Request Understanding**: Parse player requests ("follow me", "mine diamonds")
3. **Dialogue Manager**: Multi-turn conversations
4. **Task Decomposition**: Full goal â†’ task â†’ action pipeline
5. **Skill Execution**: Proper skill-based action execution

**Estimated completion**: 2-3 weeks

---

## References

1. **ReAct**: [Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
2. **Voyager**: [Lifelong Learning Agent in Minecraft](https://arxiv.org/abs/2305.16291)
3. **Memory Systems**: Inspired by human cognitive architecture (Atkinson-Shiffrin model)
4. **AutoGPT**: Autonomous agent architecture

---

## Summary

Phase 3 successfully transforms AI players into intelligent agents with:

âœ… Three-tier memory system (working + episodic + semantic)
âœ… LLM-powered planning (OpenAI/Claude/Local)
âœ… Skill library with success tracking
âœ… Goal-based decision making (ReAct framework)
âœ… Response caching (cost reduction)
âœ… Fallback to simple mode (if LLM unavailable)

**Total**: 18 new files, ~3,400 lines of code

The AI players can now:
- Remember important events and facts
- Form goals based on current situation
- Plan sequences of actions using LLM
- Learn which skills work best
- Make intelligent decisions autonomously

**Next**: Phase 4 - Natural Language Communication ğŸ—£ï¸
